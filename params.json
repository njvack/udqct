{"name":"Udqct","tagline":"Untitled Data Quality Check Tool","body":"# udqct\r\nThe Untitled Data Quality Check Tool\r\n\r\n## Overview\r\n\r\nThe purpose of this is to be able to quickly find Points of Concern in spreadsheets of data. It's to let you know about outliers and missing data *before* you get all excited about that regression you ran (but haven't looked a the scatterplot).\r\n\r\nIt should show the *type* of data you have: show whether it is *identifying* (unique or nearly so), *categorical* (eg, group assignment), *continuous* (can take many values), *ordinal* (ordered, but not so many values), or *missing.*\r\n\r\n*We'll need heuristics for detecting these. Do we need to differentiate between Ordinal and Continuous in this tool?*\r\n\r\nTarget data size is in the 300 rows by 1000 columns neighborhood. *What do we do with data much larger than this?*\r\n\r\nBasic layout will probably be a grid, with cells colored by data type. Continuous (and ordinal?) columns are be colored with a diverging color ramp corresponding to the demeaned, z-scored value. Most values will be very close to the center of this scale; outliers will get a big jump to the extreme ends. *Or maybe there won't be a color ramp for non-outlier points? Do we care about how that distribution looks by color? Will people be tempted to see non-useful patterns? If you can sort, this might be more useful.*\r\n\r\nCategorical data will get colors (from the same family) for each value, to show general variability. *Or maybe no ramp for categorical points, either; just the same color?*\r\n\r\nIdentifying data will be shown in a single (muted) color.\r\n\r\nMissing data will be shown in a single (distinct) color.\r\n\r\nANYHOW essentially color will be how you tell if a cell is *identifying,* *normal,* *outlying,* or *missing.* I think that's the essential distinction. Indicating low/high outlying points may be important, too.\r\n\r\n## What Can You Do?\r\n\r\nYou can *navigate* -- you need to be able to somehow see what you have in a substantially large data file. Probably, trying to stuff everything into one viewport won't work very well.\r\n\r\nYou can *filter* -- show only columns/rows with outlying points, also filter rows or columns with some kind of search.\r\n\r\nYou can *query* -- how many outliers are in this row? What is the distribution of values in this column? Is it significantly non-normal? What is the value of this cell and where is it on the column's overall distribution?\r\n\r\nYou can *censor* -- if I leave a cell's value out, how does the column's distribution change? Mainly, this will be to alleviate scaling problems in viweing the distribution.\r\n\r\nYou can *describe* -- choose a set of columns to act as a human-readable identifier.\r\n\r\nYou can *share* your current view with other people, by sending a link. *Maybe this is dumb and not useful?*\r\n\r\n## What *Can't* You Do?\r\n\r\nYou can't change values.\r\n\r\nYou can't impute values.\r\n\r\nYou can't annotate things, or keep any complex state. This is not a lab notebook.\r\n\r\nYou (probably?) can't download the data.\r\n\r\nYou can't download a picture of the data. This would be dumb.\r\n\r\n## Implementation\r\n\r\nBackend is (probably) python+flask+pandas+pytables. Frontend is HTML5. Render in maybe HTML table; canvas or webgl if necessary for \"decent\" performance. \"Decent\" means not laggy-feeling on my 5-year-old Air and Chrome with a 300x1000 dataset.\r\n\r\nData is input either as an uploaded CSV (Excel?) file, or as a URL to one. It'll be downloaded, put in a dataframe, and saved to disk. We'll generate a scatterize-like unique URL and redirect to that.\r\n\r\nIt will probably make sense to do some diagnostic stuff in python (find outliers, classify columns, etc) and then send the data (as JSON?) up to the client for rendering.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}